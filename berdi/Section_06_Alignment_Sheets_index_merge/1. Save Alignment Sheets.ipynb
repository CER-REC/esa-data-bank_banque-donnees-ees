{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fitz\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"c:\\\\Users\\\\t1nipun\\\\Desktop\\\\BERDI\\\\esa-data-bank_banque-donnees-ees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reading the Index 1 file - Dataframe\n",
    "path = os.getcwd()\n",
    "\n",
    "#features = pd.read_csv(path + '\\\\data\\\\processed\\\\page_features\\\\all_features.csv', index_col = 0, encoding= 'unicode_escape')\n",
    "features = pd.read_csv(path + '\\\\data\\\\processed\\\\page_features\\\\all_features.csv', index_col = 0)\n",
    "print(len(features))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_features = features.copy()\n",
    "#X_df_features.drop(columns=['dataID_pageNo', 'result'], inplace=True)\n",
    "X_df_features.drop(columns=['dataID', 'pageNo', 'paths_l'], inplace=True)\n",
    "X_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_path = path + '\\\\models\\\\alignment_sheet_classifier_rfc.sav'\n",
    "loaded_model = pickle.load(open(m_path, 'rb'))\n",
    "result = loaded_model.predict(X_df_features)\n",
    "\n",
    "y_predict = []\n",
    "for y in result:\n",
    "    if y > 0.50:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)\n",
    "        \n",
    "print(len(y_predict))\n",
    "print(y_predict[:5])\n",
    "print(sum(y_predict))\n",
    "\n",
    "features[\"results\"] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_sheets = features[features.results > 0.5]\n",
    "print(\"Total number of Pages: \", len(features))\n",
    "print(\"Total number of Alignment Sheets: \", len(alignment_sheets))\n",
    "alignment_sheets.reset_index(drop=True, inplace=True)\n",
    "alignment_sheets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_sheets_list = []\n",
    "for index, row in alignment_sheets.iterrows():\n",
    "    al = str(row[\"dataID\"]) + \"_\" + str(row[\"pageNo\"])\n",
    "    alignment_sheets_list.append(al)\n",
    "    \n",
    "print(len(alignment_sheets_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if alignment sheets were previously extracted as Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_file = pd.read_csv(path + \"Data_Files_v2\\\\book1.csv\", index_col = 0, encoding= 'unicode_escape')\n",
    "index_file = pd.read_csv(path + '\\\\berdi\\\\Section_03_Table_and_Figure_Title_Extraction\\\\table_figs_index.csv')\n",
    "print(len(index_file))\n",
    "index_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in index_file.iterrows():\n",
    "    dataID_value = row[\"PDF Download URL\"].split(\"/\")[-1]\n",
    "    pageno_value = row[\"PDF Page Number\"]\n",
    "    sheet = str(dataID_value) + \"_\" + str(pageno_value)\n",
    "    if sheet in alignment_sheets_list:\n",
    "        alignment_sheets_list.remove(sheet)\n",
    "        \n",
    "        index_file.loc[index, 'Content Type'] = \"Alignment Sheet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alignment_sheets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_count = 0\n",
    "for index, row in index_file.iterrows():\n",
    "    if \"Alignment Sheet\"  in row[\"Content Type\"]:\n",
    "        as_count = as_count+1\n",
    " \n",
    "print(as_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the rest of the alignment sheets - Extract the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def count_digits_in_string(word):\n",
    "    digit_count = 0\n",
    "    for a in word:\n",
    "        if a.isdigit():\n",
    "            digit_count = digit_count + 1\n",
    "    return(digit_count)\n",
    "\n",
    "def get_alignment_sheet_title(dataID, pageNo, path):\n",
    "    path_pkl = path + '\\\\data\\\\processed\\\\pickle_files\\\\' + str(dataID) + \".pkl\"\n",
    "    title_found = 0\n",
    "    table_title = \"\"\n",
    "    table_title_next = \"\"\n",
    "    ytest_no_blanks = \"\"\n",
    "    last_ptag_starts_with_key = 0    \n",
    "    with open(path_pkl, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        soup = BeautifulSoup(data['content'], 'lxml')\n",
    "        pages = soup.find_all('div', attrs={'class': 'page'})\n",
    "        for b, p in enumerate(pages):\n",
    "            if b != pageNo - 1:\n",
    "                continue\n",
    "                \n",
    "            #print(dataID, pageNo)\n",
    "                \n",
    "            pages_text = [x.text for x in p.find_all('p')]\n",
    "            for y in pages_text:\n",
    "                    \n",
    "                pages_text = [x.text for x in p.find_all('p')]\n",
    "                for y in pages_text:\n",
    "                    ytest = y.replace('\\n','').replace('\\r','')\n",
    "                    ytest = ytest.split(\" \")\n",
    "                    ytest_no_blanks = \"\"\n",
    "                    for ytes in ytest:\n",
    "                        if len(ytes) > 2:\n",
    "                            ytest_no_blanks = ytest_no_blanks + ytes + \" \"\n",
    "                            \n",
    "                    if last_ptag_starts_with_key ==1:\n",
    "                        table_title_next = (y.replace('\\n',' ').replace('\\r',''))\n",
    "                        break\n",
    "                        \n",
    "                    if ytest_no_blanks.startswith(('FIGURE', 'Figure', 'PHOTO', 'Photo')):\n",
    "                        #and not any(substring in y for substring in exceptions_list):\n",
    "                        table_title = y.replace('\\n','').replace('\\r','')\n",
    "                        last_ptag_starts_with_key = 1\n",
    "                        title_found = 1\n",
    "                        \n",
    "        alternate_title = \"Alignment Sheet \" + str(dataID) + \" \" + str(pageNo)\n",
    "        return(table_title, table_title_next, alternate_title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decide_title(table_title, table_title_next, alternate_title):\n",
    "     \n",
    "#     table_string = table_title.replace('\\n','').replace('\\r','').replace('â€“',\"\").replace(\":\",\"\").replace(\"-\",\"\").replace(\"(\",\"\")\n",
    "#     table_string = table_string.replace('.','')\n",
    "#     category = 0\n",
    "        \n",
    "#     title_words = re.split(\" \", table_string)\n",
    "        \n",
    "#     title_words_no_blanks = []\n",
    "#     for title_word in title_words:\n",
    "#         if len(title_word) > 2:\n",
    "#             title_words_no_blanks.append(title_word)\n",
    "#         elif len(title_word) > 0 and count_digits_in_string(title_word) > 0:\n",
    "#                 title_words_no_blanks.append(title_word)\n",
    "                \n",
    "    \n",
    "        \n",
    "#     category = 0\n",
    "#     if len(title_words_no_blanks) < 3: \n",
    "#             category = 0.75\n",
    "            \n",
    "#     if 'cont' in table_string.lower():\n",
    "#         category = 0.35\n",
    "            \n",
    "        \n",
    "#     #category2 = 0\n",
    "#     if len(title_words_no_blanks) > 2:\n",
    "#         if(title_words_no_blanks[2][0].isupper() or title_words_no_blanks[2][0].isdigit()):\n",
    "#             category = 1\n",
    "#         else:\n",
    "#             category = 0\n",
    "#         if(title_words_no_blanks[1][-1]== ',') or (title_words_no_blanks[1][-1]== ']') or (title_words_no_blanks[1][-1]== ')'):\n",
    "#             category = 0\n",
    "#         if(title_words_no_blanks[2][:4].lower() == 'cont'):\n",
    "#                 category = 0.35\n",
    "            \n",
    "#     if len(title_words_no_blanks) == 3 :\n",
    "#         category = 0.5\n",
    "#         if(title_words_no_blanks[1][0].isdigit() and  title_words_no_blanks[1][0].isupper()):\n",
    "#             category = 0.65\n",
    "#         if(title_words_no_blanks[2][0].lower() == 'c'):\n",
    "#             category = 0.55\n",
    "#         if(title_words_no_blanks[2][:4].lower() == 'cont'):\n",
    "#             category = 0.35\n",
    "            \n",
    "#     if category < 0.5 or len(title_words_no_blanks) < 6 or count_digits_in_string(title_words_no_blanks) > 10:\n",
    "#         return(alternate_title, 0)\n",
    "#     elif category < 0.7:\n",
    "#         return(table_title + table_title_next, 1)\n",
    "#     else:\n",
    "#         return(table_title, 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_title(table_title, table_title_next, alternate_title):\n",
    "    \n",
    "    if count_digits_in_string(table_title) > 10:\n",
    "        return(alternate_title, 0)\n",
    "     \n",
    "    table_string = table_title.replace('\\n','').replace('\\r','').replace('â€“',\"\").replace(\":\",\"\").replace(\"-\",\"\").replace(\"(\",\"\")\n",
    "    table_string = table_string.replace('.','')\n",
    "    category = 0\n",
    "        \n",
    "    title_words = table_string.split()\n",
    "        \n",
    "    title_words_no_blanks = []\n",
    "    for title_word in title_words:\n",
    "        if len(title_word) > 2:\n",
    "            title_words_no_blanks.append(title_word)\n",
    "                \n",
    "    category = 0\n",
    "    if len(title_words_no_blanks) < 3: \n",
    "        category = 0.45\n",
    "            \n",
    "    if 'cont' in table_string.lower():\n",
    "        category = 0.35\n",
    "            \n",
    "        \n",
    "    #category2 = 0\n",
    "    if len(title_words_no_blanks) > 2:\n",
    "        if(title_words_no_blanks[2][0].isupper() or title_words_no_blanks[2][0].isdigit()):\n",
    "            category = 1\n",
    "        else:\n",
    "            category = 0\n",
    "        if(title_words_no_blanks[1][-1]== ',') or (title_words_no_blanks[1][-1]== ']') or (title_words_no_blanks[1][-1]== ')'):\n",
    "            category = 0\n",
    "        if(title_words_no_blanks[2][:4].lower() == 'cont'):\n",
    "            category = 0.35\n",
    "            \n",
    "    if len(title_words_no_blanks) == 3 :\n",
    "        category = 0.5\n",
    "        if(title_words_no_blanks[1][0].isdigit() and  title_words_no_blanks[1][0].isupper()):\n",
    "            category = 0.65\n",
    "        if(title_words_no_blanks[2][0].lower() == 'c'):\n",
    "            category = 0.55\n",
    "        if(title_words_no_blanks[2][:4].lower() == 'cont'):\n",
    "            category = 0.35\n",
    "            \n",
    "    if category < 0.5 or len(title_words_no_blanks) < 6 or count_digits_in_string(title_words_no_blanks) > 10:\n",
    "        return(alternate_title, 0)\n",
    "    elif category < 0.7:\n",
    "        return(table_title + table_title_next, 1)\n",
    "    else:\n",
    "        return(table_title, 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Ref-> https://github.com/CER-REC/esa-data-bank_banque-donnees-ees/blob/3a59e33b1ee9a37857380387d7c380e9139eedbf/Codes/TableCategorization.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for alignment_s in alignment_sheets_list:\n",
    "#     dataid_alignment_s, pageno_alignment_s = alignment_s.split(\"_\")\n",
    "#     table_title, table_title_next, alternate_title = get_alignment_sheet_title(int(dataid_alignment_s), int(pageno_alignment_s), path)\n",
    "#     a, b = decide_title(table_title, table_title_next, alternate_title)\n",
    "#     print(dataid_alignment_s, pageno_alignment_s,\"------Final Title: \",b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Content_Type = []\n",
    "PDF_Page_Number = []\n",
    "Data_ID = []\n",
    "#thumbnail_location = []\n",
    "needs_translation = []\n",
    "\n",
    "\n",
    "#alignment_sheets_list = alignment_sheets_list[:50]\n",
    "count = 0\n",
    "for alignment_s in alignment_sheets_list:\n",
    "    #print(\"_____________\", count, \" of \", len(alignment_sheets_list) )\n",
    "    count = count +1\n",
    "    dataid_alignment_s, pageno_alignment_s = alignment_s.split(\"_\")\n",
    "    \n",
    "    #Extrct the title of the alignment sheet\n",
    "    table_title, table_title_next, alternate_title = get_alignment_sheet_title(int(dataid_alignment_s), int(pageno_alignment_s), path)\n",
    "    titl, needs_transla = decide_title(table_title, table_title_next, alternate_title)\n",
    "    #print(needs_transla, titl)\n",
    "    Title.append(titl)\n",
    "    needs_translation.append(needs_transla)\n",
    "    Content_Type.append(str(\"Alignment Sheet\"))\n",
    "    PDF_Page_Number.append(int(pageno_alignment_s))\n",
    "    Data_ID.append(int(dataid_alignment_s))\n",
    "    #thumbnail_location.append(\"thumbnails\\\\\"+ alignment_s + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in alignment_sheets.iterrows():\n",
    "#     Id.append(str(row[\"dataID\"]) + \"_\" + str(row[\"pageNo\"]) + \"_A\")\n",
    "#     #print(\"alignment_sheets_thumbnails\\\\\"+ str(row[\"dataID\"]) + \"_\" +str(row[\"pageNo\"])+ \".jpg\")\n",
    "    \n",
    "as_index_for_translation = pd.DataFrame({'Title' : Title, \n",
    "                                         'ID' : alignment_sheets_list,\n",
    "                                         'Needs_Translation': needs_translation})\n",
    "print(len(as_index_for_translation))\n",
    "as_index_for_translation = as_index_for_translation[as_index_for_translation.Needs_Translation > 0.5]\n",
    "as_index_for_translation.drop('Needs_Translation', \n",
    "                               axis=1, \n",
    "                               inplace=True)\n",
    "\n",
    "as_index_for_translation.to_csv(path + \"\\\\data\\\\interim\\\\alignment_sheet_files\\\\new_alignment_sheet_titles_for_translation.csv\",\n",
    "                               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(as_index_for_translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the rest of the alignment sheets - Extract Other Index Coloumn Values from PDF Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Application Short Name</th>\n",
       "      <th>Application Filing Date</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>File Name</th>\n",
       "      <th>ESA Folder URL</th>\n",
       "      <th>Document Number</th>\n",
       "      <th>DataID</th>\n",
       "      <th>...</th>\n",
       "      <th>Pipeline Status</th>\n",
       "      <th>Regulatory Instrument(s)</th>\n",
       "      <th>Application URL</th>\n",
       "      <th>Decision URL</th>\n",
       "      <th>ESA Section(s)</th>\n",
       "      <th>ESA Section(s) Index</th>\n",
       "      <th>Topics</th>\n",
       "      <th>PDF Size (bytes)</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Outline Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-19 - Application for the Sinclair Pipe...</td>\n",
       "      <td>Application for the Sinclair Pipeline Project</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>Steel Reef Pipelines Canada Corp.</td>\n",
       "      <td>Gas</td>\n",
       "      <td>C15521-7 Environmental and Socio-Economic Asse...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>A7X5Q9</td>\n",
       "      <td>4160317</td>\n",
       "      <td>...</td>\n",
       "      <td>Approved</td>\n",
       "      <td>XG-006-2022</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>Introduction, Project Description, Consultatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Land', 'Air', 'Water', 'Wildlife', 'Vegetati...</td>\n",
       "      <td>9980785</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-19 - Application for the Sinclair Pipe...</td>\n",
       "      <td>Application for the Sinclair Pipeline Project</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>Steel Reef Pipelines Canada Corp.</td>\n",
       "      <td>Gas</td>\n",
       "      <td>C15521-8 Environmental and Socio-Economic Asse...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>A7X5R0</td>\n",
       "      <td>4159893</td>\n",
       "      <td>...</td>\n",
       "      <td>Approved</td>\n",
       "      <td>XG-006-2022</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>Appendix 1A Pipeline Environmental Protection ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Human', 'Environment Protection Plan']</td>\n",
       "      <td>9606854</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-19 - Application for the Sinclair Pipe...</td>\n",
       "      <td>Application for the Sinclair Pipeline Project</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>Steel Reef Pipelines Canada Corp.</td>\n",
       "      <td>Gas</td>\n",
       "      <td>C15521-9 Environmental and Socio-Economic Asse...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>A7X5R1</td>\n",
       "      <td>4160083</td>\n",
       "      <td>...</td>\n",
       "      <td>Approved</td>\n",
       "      <td>XG-006-2022</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>Appendix 1B Facility Environmental Protection ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Land', 'Vegetation', 'Human', 'Technology', ...</td>\n",
       "      <td>7757174</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-19 - Application for the Sinclair Pipe...</td>\n",
       "      <td>Application for the Sinclair Pipeline Project</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>Steel Reef Pipelines Canada Corp.</td>\n",
       "      <td>Gas</td>\n",
       "      <td>C15521-10 Environmental and Socio-Economic Ass...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>A7X5R2</td>\n",
       "      <td>4160318</td>\n",
       "      <td>...</td>\n",
       "      <td>Approved</td>\n",
       "      <td>XG-006-2022</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>Appendix 3 Vegetation Technical Data Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Vegetation', 'Human', 'Technology']</td>\n",
       "      <td>8285879</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-19 - Application for the Sinclair Pipe...</td>\n",
       "      <td>Application for the Sinclair Pipeline Project</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>Steel Reef Pipelines Canada Corp.</td>\n",
       "      <td>Gas</td>\n",
       "      <td>C15521-11 Environmental and Socio-Economic Ass...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>A7X5R3</td>\n",
       "      <td>4160453</td>\n",
       "      <td>...</td>\n",
       "      <td>Approved</td>\n",
       "      <td>XG-006-2022</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...</td>\n",
       "      <td>Appendix 4 Fish and Fish Habitat Technical Dat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Land', 'Water', 'Wildlife', 'Vegetation', 'H...</td>\n",
       "      <td>8644541</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    application_name  \\\n",
       "0  2021-10-19 - Application for the Sinclair Pipe...   \n",
       "1  2021-10-19 - Application for the Sinclair Pipe...   \n",
       "2  2021-10-19 - Application for the Sinclair Pipe...   \n",
       "3  2021-10-19 - Application for the Sinclair Pipe...   \n",
       "4  2021-10-19 - Application for the Sinclair Pipe...   \n",
       "\n",
       "                                Application Name Application Short Name  \\\n",
       "0  Application for the Sinclair Pipeline Project               Sinclair   \n",
       "1  Application for the Sinclair Pipeline Project               Sinclair   \n",
       "2  Application for the Sinclair Pipeline Project               Sinclair   \n",
       "3  Application for the Sinclair Pipeline Project               Sinclair   \n",
       "4  Application for the Sinclair Pipeline Project               Sinclair   \n",
       "\n",
       "  Application Filing Date                       Company Name Commodity  \\\n",
       "0              10/19/2021  Steel Reef Pipelines Canada Corp.       Gas   \n",
       "1              10/19/2021  Steel Reef Pipelines Canada Corp.       Gas   \n",
       "2              10/19/2021  Steel Reef Pipelines Canada Corp.       Gas   \n",
       "3              10/19/2021  Steel Reef Pipelines Canada Corp.       Gas   \n",
       "4              10/19/2021  Steel Reef Pipelines Canada Corp.       Gas   \n",
       "\n",
       "                                           File Name  \\\n",
       "0  C15521-7 Environmental and Socio-Economic Asse...   \n",
       "1  C15521-8 Environmental and Socio-Economic Asse...   \n",
       "2  C15521-9 Environmental and Socio-Economic Asse...   \n",
       "3  C15521-10 Environmental and Socio-Economic Ass...   \n",
       "4  C15521-11 Environmental and Socio-Economic Ass...   \n",
       "\n",
       "                                      ESA Folder URL Document Number   DataID  \\\n",
       "0  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...          A7X5Q9  4160317   \n",
       "1  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...          A7X5R0  4159893   \n",
       "2  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...          A7X5R1  4160083   \n",
       "3  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...          A7X5R2  4160318   \n",
       "4  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...          A7X5R3  4160453   \n",
       "\n",
       "   ... Pipeline Status Regulatory Instrument(s)  \\\n",
       "0  ...        Approved              XG-006-2022   \n",
       "1  ...        Approved              XG-006-2022   \n",
       "2  ...        Approved              XG-006-2022   \n",
       "3  ...        Approved              XG-006-2022   \n",
       "4  ...        Approved              XG-006-2022   \n",
       "\n",
       "                                     Application URL  \\\n",
       "0  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "1  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "2  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "3  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "4  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "\n",
       "                                        Decision URL  \\\n",
       "0  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "1  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "2  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "3  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "4  https://apps.cer-rec.gc.ca/REGDOCS/Item/View/4...   \n",
       "\n",
       "                                      ESA Section(s) ESA Section(s) Index  \\\n",
       "0  Introduction, Project Description, Consultatio...                  NaN   \n",
       "1  Appendix 1A Pipeline Environmental Protection ...                  NaN   \n",
       "2  Appendix 1B Facility Environmental Protection ...                  NaN   \n",
       "3        Appendix 3 Vegetation Technical Data Report                  NaN   \n",
       "4  Appendix 4 Fish and Fish Habitat Technical Dat...                  NaN   \n",
       "\n",
       "                                              Topics PDF Size (bytes)  \\\n",
       "0  ['Land', 'Air', 'Water', 'Wildlife', 'Vegetati...          9980785   \n",
       "1           ['Human', 'Environment Protection Plan']          9606854   \n",
       "2  ['Land', 'Vegetation', 'Human', 'Technology', ...          7757174   \n",
       "3              ['Vegetation', 'Human', 'Technology']          8285879   \n",
       "4  ['Land', 'Water', 'Wildlife', 'Vegetation', 'H...          8644541   \n",
       "\n",
       "  Number of Pages Outline Present  \n",
       "0             362               1  \n",
       "1             208               1  \n",
       "2             141               1  \n",
       "3              92               1  \n",
       "4             102               1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_pdf_df = pd.read_csv(path + '\\\\data\\\\interim\\\\Intermediate_Index_Files\\\\Phase3_Index_of_PDFs_for_Major_Projects_with_ESAs.csv')\n",
    "index_pdf_df = index_pdf_df.rename(columns={\"Data ID\": \"DataID\"})\n",
    "index_pdf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_Name = []\n",
    "Application_Short_Name = []\n",
    "Application_Filing_Date = []\n",
    "Company_Name = []\n",
    "Commodity = []\n",
    "File_Name = []\n",
    "ESA_Folder_URL =[]\n",
    "Document_Number = []\n",
    "PDF_Download_URL =[]\n",
    "Application_Type = []\n",
    "Pipeline_Location =[]\n",
    "Hearing_order =[]\n",
    "Consultant_Name =[]\n",
    "Pipeline_Status =[]\n",
    "Regulatory_Instrument =[]\n",
    "Application_URL =[]\n",
    "Decision_URL =[]\n",
    "ESA_Section = []\n",
    "ESA_Section_Index = []\n",
    "ESA_Section_Topics = []\n",
    "PDF_Page_Count =[]\n",
    "PDF_Size = []\n",
    "PDF_Outline = []\n",
    "# Landscape_terrain_and_weather = []\n",
    "# Soil = []\n",
    "# Plants = []\n",
    "# Water =[]\n",
    "# Fish = []\n",
    "# Wetlands = []\n",
    "# Wildlife = []\n",
    "# Species_at_Risk = []\n",
    "# Greenhouse_gas_emissions = []\n",
    "# Air_emissions = []\n",
    "# Noise = []\n",
    "# Electricity_and_electromagnetism = []\n",
    "# Proximity_to_people = []\n",
    "# Archaeological_aleontological = []\n",
    "# Human_access  = []\n",
    "# Indigenous_land_water_and_air_use = []\n",
    "# Impact_to_social_and_cultural_well_being = []\n",
    "# Impact_to_human_health_and_viewscapes = []\n",
    "# Social_cultural_economic_infrastructure_and_services = []\n",
    "# Economic_Offsets_and_Impact = []\n",
    "# Environmental_Obligations = []\n",
    "# Treaty_and_Indigenous_Rights = []\n",
    "# Project_Download_Path = []\n",
    "# Table_Download_Path = []\n",
    "# Good_Quality = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_name\n",
      "Application Name\n",
      "Application Short Name\n",
      "Application Filing Date\n",
      "Company Name\n",
      "Commodity\n",
      "File Name\n",
      "ESA Folder URL\n",
      "Document Number\n",
      "DataID\n",
      "PDF Download URL\n",
      "Application Type\n",
      "Pipeline Location\n",
      "Hearing Order\n",
      "Consultant Name\n",
      "Pipeline Status\n",
      "Regulatory Instrument(s)\n",
      "Application URL\n",
      "Decision URL\n",
      "ESA Section(s)\n",
      "ESA Section(s) Index\n",
      "Topics\n",
      "PDF Size (bytes)\n",
      "Number of Pages\n",
      "Outline Present\n"
     ]
    }
   ],
   "source": [
    "col = []\n",
    "for columns in index_pdf_df:\n",
    "    col.append(columns)\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_df = index_pdf_df[index_pdf_df.DataID == 268706]\n",
    "pdf_df[\"Company Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4159893_199',\n",
       " '4159893_200',\n",
       " '4159893_201',\n",
       " '4159893_202',\n",
       " '4159893_203',\n",
       " '4159893_204',\n",
       " '4159893_205',\n",
       " '4159893_206',\n",
       " '4159893_207',\n",
       " '4159893_208']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_sheets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pdf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alignment_s in alignment_sheets_list:\n",
    "    dataid_alignment_s, pageno_alignment_s = alignment_s.split(\"_\")\n",
    "    \n",
    "    pdf_df = index_pdf_df[index_pdf_df.DataID == int(dataid_alignment_s)]\n",
    "    if len(pdf_df) ==0:\n",
    "        print(\"DataID not found in pdf index: \", dataid_alignment_s)\n",
    "        continue\n",
    "    if len(pdf_df) > 1:\n",
    "        print(\"Duplicate DataIDs found in pdf index: \", dataid_alignment_s)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    Application_Name.append(pdf_df[\"Application Name\"].iloc[0])\n",
    "    Application_Short_Name.append(pdf_df[\"Application Short Name\"].iloc[0])\n",
    "    Application_Filing_Date.append(pdf_df[\"Application Filing Date\"].iloc[0])\n",
    "    Company_Name.append(pdf_df[\"Company Name\"].iloc[0])\n",
    "    Commodity.append(pdf_df[\"Commodity\"].iloc[0])\n",
    "    File_Name.append(pdf_df[\"File Name\"].iloc[0])\n",
    "    ESA_Folder_URL.append(pdf_df[\"ESA Folder URL\"].iloc[0])\n",
    "    Document_Number.append(pdf_df[\"Document Number\"].iloc[0])\n",
    "    PDF_Download_URL.append(pdf_df[\"PDF Download URL\"].iloc[0])\n",
    "    Application_Type.append(pdf_df[\"Application Type\"].iloc[0])\n",
    "    Pipeline_Location.append(pdf_df[\"Pipeline Location\"].iloc[0])\n",
    "    Hearing_order.append(pdf_df[\"Hearing Order\"].iloc[0])\n",
    "    Consultant_Name.append(pdf_df[\"Consultant Name\"].iloc[0])\n",
    "    Pipeline_Status.append(pdf_df[\"Pipeline Status\"].iloc[0])\n",
    "    Regulatory_Instrument.append(pdf_df[\"Regulatory Instrument(s)\"].iloc[0])\n",
    "    Application_URL.append(pdf_df[\"Application URL\"].iloc[0])\n",
    "    Decision_URL.append(pdf_df[\"Decision URL\"].iloc[0])\n",
    "    ESA_Section.append(pdf_df[\"ESA Section(s)\"].iloc[0])\n",
    "    ESA_Section_Index.append(pdf_df[\"ESA Section(s) Index\"].iloc[0])\n",
    "    ESA_Section_Topics.append(pdf_df[\"Topics\"].iloc[0])\n",
    "    PDF_Page_Count.append(pdf_df[\"Number of Pages\"].iloc[0])\n",
    "    PDF_Size.append(pdf_df[\"PDF Size (bytes)\"].iloc[0])\n",
    "    PDF_Outline.append(pdf_df[\"Outline Present\"].iloc[0])\n",
    "    # Landscape_terrain_and_weather.append(np.nan)\n",
    "    # Soil.append(np.nan)\n",
    "    # Plants.append(np.nan)\n",
    "    # Water.append(np.nan)\n",
    "    # Fish.append(np.nan)\n",
    "    # Wetlands.append(np.nan)\n",
    "    # Wildlife.append(np.nan)\n",
    "    # Species_at_Risk.append(np.nan)\n",
    "    # Greenhouse_gas_emissions.append(np.nan)\n",
    "    # Air_emissions.append(np.nan)\n",
    "    # Noise.append(np.nan)\n",
    "    # Electricity_and_electromagnetism.append(np.nan)\n",
    "    # Proximity_to_people.append(np.nan)\n",
    "    # Archaeological_aleontological.append(np.nan)\n",
    "    # Human_access.append(np.nan)\n",
    "    # Indigenous_land_water_and_air_use.append(np.nan)\n",
    "    # Impact_to_social_and_cultural_well_being.append(np.nan)\n",
    "    # Impact_to_human_health_and_viewscapes.append(np.nan)\n",
    "    # Social_cultural_economic_infrastructure_and_services.append(np.nan)\n",
    "    # Economic_Offsets_and_Impact.append(np.nan)\n",
    "    # Environmental_Obligations.append(np.nan)\n",
    "    # Treaty_and_Indigenous_Rights.append(np.nan)\n",
    "    \n",
    "    # Project_Download_Path.append(np.nan)\n",
    "    # Table_Download_Path.append(np.nan)\n",
    "    # Good_Quality.append(np.nan)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title))\n",
    "print(len(Content_Type))\n",
    "print(len(Application_Name))\n",
    "print(len(PDF_Outline))\n",
    "#print(len(Project_Download_Path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pdf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_as_df = pd.DataFrame({'Title' : Title, \n",
    "                            'Content Type' : Content_Type, \n",
    "                            'Application Name' : Application_Name,\n",
    "                            'Application Short Name' : Application_Short_Name, \n",
    "                            'Application Filing Date' :Application_Filing_Date, \n",
    "                            'Company Name' : Company_Name, \n",
    "                            'Commodity' :  Commodity, \n",
    "                            'File Name' : File_Name, \n",
    "                            'ESA Folder URL' : ESA_Folder_URL, \n",
    "                            'Document Number' : Document_Number, \n",
    "                            'Data ID' : Data_ID, \n",
    "                            'PDF Download URL' : PDF_Download_URL, \n",
    "                            'Application Type' : Application_Type, \n",
    "                            'Pipeline Location' : Pipeline_Location, \n",
    "                            'Hearing Order' : Hearing_order, \n",
    "                            'Consultant Name' : Company_Name, \n",
    "                            'Pipeline Status' : Pipeline_Status, \n",
    "                            'Regulatory Instrument(s)' : Regulatory_Instrument, \n",
    "                            'Application URL' : Application_URL,\n",
    "                            'Decision URL': Decision_URL, \n",
    "                            'ESA Section(s)' : ESA_Section, \n",
    "                            'ESA Section(s) Index' : ESA_Section_Index, \n",
    "                            'Topics' : ESA_Section_Topics, \n",
    "                            'PDF Page Number' : PDF_Page_Number, #Keep this \n",
    "                            'PDF Page Count' : PDF_Page_Count, \n",
    "                            'PDF Size (bytes)' : PDF_Size, \n",
    "                            'Outline Present' : PDF_Outline,\n",
    "                            \n",
    "                            \n",
    "                            # 'Landscape, terrain, and weather' : Landscape_terrain_and_weather,\n",
    "                            # 'Soil' : Soil,\n",
    "                            # 'Plants' : Plants,\n",
    "                            # 'Water' : Water, \n",
    "                            # 'Fish' : Fish,\n",
    "                            # 'Wetlands' : Wetlands,\n",
    "                            # 'Wildlife' : Wildlife, \n",
    "                            # 'Species at Risk' : Species_at_Risk, \n",
    "                            # 'Greenhouse gas emissions' : Greenhouse_gas_emissions,\n",
    "                            # 'Air emissions' : Air_emissions,\n",
    "                            # 'Noise' : Noise,\n",
    "                            # 'Electricity and electromagnetism' : Electricity_and_electromagnetism,\n",
    "                            # 'Proximity to people' : Proximity_to_people,\n",
    "                            # 'Archaeological, paleontological, historical, and culturally significant sites and resources' : Archaeological_aleontological,\n",
    "                            # 'Human access to boats and waterways' : Human_access,\n",
    "                            # 'Indigenous land, water, and air use' : Indigenous_land_water_and_air_use,\n",
    "                            # 'Impact to social and cultural well-being' : Impact_to_social_and_cultural_well_being,\n",
    "                            # 'Impact to human health and viewscapes' : Impact_to_human_health_and_viewscapes,\n",
    "                            # 'Social, cultural, economic infrastructure and services': Social_cultural_economic_infrastructure_and_services,\n",
    "                            # 'Economic Offsets and Impact' : Economic_Offsets_and_Impact, \n",
    "                            # 'Environmental Obligations' : Environmental_Obligations,\n",
    "                            # 'Treaty and Indigenous Rights' : Treaty_and_Indigenous_Rights,\n",
    "                            \n",
    "                            \n",
    "                            # 'Project Download Path' : Project_Download_Path, \n",
    "                            # 'Table Download Path' : Table_Download_Path, \n",
    "                            # 'Good Quality': Good_Quality,\n",
    "                            })\n",
    "\n",
    "index_as_df.to_csv(path + \"\\\\data\\\\interim\\\\alignment_sheet_files\\\\Index_Alignment_Sheets_try.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with the index file of tables and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_fig_align_index = index_file.append(index_as_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ID and ID Internal Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_table_fig_align_index['alignNumber'] = df_table_fig_align_index['Content Type'].apply(lambda x: int(1) if x == 'Alignment Sheet' else '')\n",
    "df_table_fig_align_index.insert(len(df_table_fig_align_index.columns), 'ID', range(21425, 21425 + len(df_table_fig_align_index)))\n",
    "df_table_fig_align_index['ID Internal'] = ''\n",
    "for idx, row in df_table_fig_align_index.iterrows():\n",
    "    if row['Content Type'] == 'Table':\n",
    "        df_table_fig_align_index.loc[idx, 'ID Internal'] = str(row['Data ID']) + '_' + str(row['PDF Page Number']) + '_t_' + str(int(row.tableNumber))\n",
    "    elif row['Content Type'] == 'Alignment Sheet':\n",
    "        df_table_fig_align_index.loc[idx, 'ID Internal'] = str(row['Data ID']) + '_' + str(row['PDF Page Number']) + '_a_' + str(int(row.alignNumber))\n",
    "    else:\n",
    "        df_table_fig_align_index.loc[idx, 'ID Internal'] = str(row['Data ID']) + '_' + str(row['PDF Page Number']) + '_f_' + str(int(row.figureNumber))\n",
    "\n",
    "#df_table_fig_align_index.to_csv(path + \"\\\\data\\\\interim\\\\Intermediate_Index_Files\\\\Table_Fig_Alignment_Index.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_fig_align_index.to_csv(path + \"\\\\data\\\\interim\\\\Intermediate_Index_Files\\\\Table_Fig_Alignment_Index.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create thumbnails for figures/tables/alignment sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thumbnail(dataID, pageNo, path):\n",
    "    \n",
    "    file_p = path + \"Data_Files_v2\\\\PDFs\\\\\"+ str(dataID) + \".pdf\"\n",
    "    doc = fitz.open(file_p)\n",
    "    for page_no in range(1, len(doc)+1):   \n",
    "        if page_no != pageNo:\n",
    "            continue\n",
    "        \n",
    "        page = doc.loadPage(page_no-1)  # number of page\n",
    "        pix = page.getPixmap()\n",
    "        \n",
    "        #Code to save the Thumbnails = 250 * 176\n",
    "        if pix.width < pix.height:\n",
    "            # scale height to 250\n",
    "            # 250 = h/ (2^n)\n",
    "            # scale_n = ln(h)/ln(2) - ln(250)/ln(2)\n",
    "            scale_n = math.log(pix.height, 2) - math.log(250, 2)\n",
    "        else:\n",
    "            scale_n = math.log(pix.width, 2) - math.log(250, 2)\n",
    "        \n",
    "        pix.shrink(round(scale_n))\n",
    "        thumb_p = file_p.replace(\"PDFs\", \"thumbnails\").replace(\".pdf\", \"_\" + str(page_no) + \".jpg\")\n",
    "        pix.writePNG(thumb_p)\n",
    "    return(thumb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_location = []\n",
    "#index_file = index_file[9000:10500]\n",
    "pdfs_with_errors = set()\n",
    "for inx, row in index.iterrows():\n",
    "    dataID_value = row[\"PDF Download URL\"].split(\"/\")[-1]\n",
    "    pageno_value = row[\"PDF Page Number\"]\n",
    "    Data_ID.append(dataID_value)\n",
    "    try:\n",
    "        get_thumbnail(int(dataID_value), int(pageno_value), path)\n",
    "        thumbnail_location.append(\"thumbnails\\\\\"+ str(dataID_value) + \"_\" +str(pageno_value)+ \".jpg\")\n",
    "    except:\n",
    "        #print(dataID_value)\n",
    "        pdfs_with_errors.add(dataID_value)\n",
    "        thumbnail_location.append(\"\")\n",
    "    #print(\"thumbnails\\\\\"+ str(dataID_value) + \"_\" +str(pageno_value)+ \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdfs_with_errors)\n",
    "print(len(pdfs_with_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_file = index_file.head(500)\n",
    "# index_file['Data ID'] = Data_ID\n",
    "index['Thumbnail Location'] = thumbnail_location\n",
    "#index_file['ID'] = ID\n",
    "#index_file.to_csv(path + \"Data_Files_v2\\\\book1_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = []\n",
    "for columns in index_file:\n",
    "    col.append(columns)\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index.sort_values(by = ['Data ID','PDF Page Number','Content Type', \"Title\"])\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ID for all the rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = index.groupby(['Data ID','PDF Page Number','Content Type'])\n",
    "countID = []\n",
    "for group in gp.groups:\n",
    "    count = 1\n",
    "    for i in gp.groups[group]:\n",
    "        countID.append(count)\n",
    "        count = count +1\n",
    "index[\"countID\"] = countID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = []\n",
    "for ind, row in index.iterrows():\n",
    "    if \"Alignment Sheet\" in row[\"Content Type\"]:\n",
    "        code = \"a\"\n",
    "    elif \"Figure\" in row[\"Content Type\"]:\n",
    "        code = \"f\"\n",
    "    elif \"Table\" in row[\"Content Type\"]:\n",
    "        code = \"t\"\n",
    "    else:\n",
    "        print(\"Error with \", row[\"Content Type\"])\n",
    "    ID.append(str(row[\"Data ID\"]) +\"_\"+ str(row[\"PDF Page Number\"]) + \"_\" + code + str(row[\"countID\"]))\n",
    "index[\"ID\"] = ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.drop('countID', \n",
    "            axis=1, \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.to_csv(path + \"Data_Files_v2\\\\index_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index))\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gp = index.groupby(['Data ID','PDF Page Number','Content Type'])\n",
    "#gp = gp[gp.Title > 3]\n",
    "# gp.groups\n",
    "\n",
    "# count = 0\n",
    "# for group in index.groupby(['Data ID','PDF Page Number','Content Type']):\n",
    "#     #print(type(group))\n",
    "#     count = count+1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('berdi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a57f819e391b0b4fe115ba667bdfe1c06f77f6806275f72654242525f22278a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
